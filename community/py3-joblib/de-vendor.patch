Upstream: Not applicable
Reason: Use system loky and cloudpickle
diff --git a/joblib/_cloudpickle_wrapper.py b/joblib/_cloudpickle_wrapper.py
index 3dbe3ae..e59e446 100644
--- a/joblib/_cloudpickle_wrapper.py
+++ b/joblib/_cloudpickle_wrapper.py
@@ -14,4 +14,4 @@ def my_wrap_non_picklable_objects(obj, keep_wrapper=True):
 if mp is None:
     wrap_non_picklable_objects = my_wrap_non_picklable_objects
 else:
-    from .externals.loky import wrap_non_picklable_objects # noqa
+    from loky import wrap_non_picklable_objects # noqa
diff --git a/joblib/_memmapping_reducer.py b/joblib/_memmapping_reducer.py
index 9d350c0..f0fdeee 100644
--- a/joblib/_memmapping_reducer.py
+++ b/joblib/_memmapping_reducer.py
@@ -34,7 +34,7 @@ except ImportError:
 from .numpy_pickle import dump, load, load_temporary_memmap
 from .backports import make_memmap
 from .disk import delete_folder
-from .externals.loky.backend import resource_tracker
+from loky.backend import resource_tracker
 
 # Some system have a ramdisk mounted by default, we can use it instead of /tmp
 # as the default folder to dump big arrays to share with subprocesses.
@@ -58,7 +58,7 @@ JOBLIB_MMAPS = set()
 
 
 def _log_and_unlink(filename):
-    from .externals.loky.backend.resource_tracker import _resource_tracker
+    from loky.backend.resource_tracker import _resource_tracker
     util.debug(
         "[FINALIZER CALL] object mapping to {} about to be deleted,"
         " decrementing the refcount of the file (pid: {})".format(
diff --git a/joblib/_parallel_backends.py b/joblib/_parallel_backends.py
index c6ec537..a93412f 100644
--- a/joblib/_parallel_backends.py
+++ b/joblib/_parallel_backends.py
@@ -21,7 +21,7 @@ if mp is not None:
     # Compat between concurrent.futures and multiprocessing TimeoutError
     from multiprocessing import TimeoutError
     from concurrent.futures._base import TimeoutError as CfTimeoutError
-    from .externals.loky import process_executor, cpu_count
+    from loky import process_executor, cpu_count
 
 
 class ParallelBackendBase(metaclass=ABCMeta):
diff --git a/joblib/executor.py b/joblib/executor.py
index 9273fed..962661f 100644
--- a/joblib/executor.py
+++ b/joblib/executor.py
@@ -10,7 +10,7 @@ copy between the parent and child processes.
 
 from ._memmapping_reducer import get_memmapping_reducers
 from ._memmapping_reducer import TemporaryResourcesManager
-from .externals.loky.reusable_executor import _ReusablePoolExecutor
+from loky.reusable_executor import _ReusablePoolExecutor
 
 
 _executor_args = None
diff --git a/joblib/externals/loky/backend/reduction.py b/joblib/externals/loky/backend/reduction.py
index f1ee394..2b81606 100644
--- a/joblib/externals/loky/backend/reduction.py
+++ b/joblib/externals/loky/backend/reduction.py
@@ -79,7 +79,7 @@ else:
 
 # global variable to change the pickler behavior
 try:
-    from joblib.externals import cloudpickle  # noqa: F401
+    import cloudpickle  # noqa: F401
     DEFAULT_ENV = "cloudpickle"
 except ImportError:
     # If cloudpickle is not present, fallback to pickle
diff --git a/joblib/parallel.py b/joblib/parallel.py
index 6e7b1b1..0aa58b7 100644
--- a/joblib/parallel.py
+++ b/joblib/parallel.py
@@ -26,7 +26,7 @@ from .disk import memstr_to_bytes
 from ._parallel_backends import (FallbackToBackend, MultiprocessingBackend,
                                  ThreadingBackend, SequentialBackend,
                                  LokyBackend)
-from .externals.cloudpickle import dumps, loads
+from cloudpickle import dumps, loads
 from ._utils import eval_expr
 
 # Make sure that those two classes are part of the public joblib.parallel API
@@ -53,7 +53,7 @@ MAYBE_AVAILABLE_BACKENDS = {'multiprocessing', 'loky'}
 # backend
 if mp is not None:
     BACKENDS['multiprocessing'] = MultiprocessingBackend
-    from .externals import loky
+    import loky
     BACKENDS['loky'] = LokyBackend
     DEFAULT_BACKEND = 'loky'
 
